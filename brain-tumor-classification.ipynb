{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2645886,"sourceType":"datasetVersion","datasetId":1608934}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Imports","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport cv2\n\nimport os\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom keras.models import Sequential\nfrom keras.layers import Dense,Dropout,Conv2D,MaxPooling2D,Flatten,InputLayer\nfrom sklearn.metrics import confusion_matrix,classification_report,ConfusionMatrixDisplay\nimport matplotlib.pyplot as plt\nfrom keras.applications import VGG19\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nimport keras.layers as L","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-03T19:55:14.300517Z","iopub.execute_input":"2024-05-03T19:55:14.301475Z","iopub.status.idle":"2024-05-03T19:55:29.488099Z","shell.execute_reply.started":"2024-05-03T19:55:14.301438Z","shell.execute_reply":"2024-05-03T19:55:29.486885Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Reading Data","metadata":{}},{"cell_type":"code","source":"def read_images(path):\n    images = []\n    labels = []\n    dirs = ['notumor','glioma','meningioma','pituitary']\n    for i,dir_ in enumerate(dirs):\n        path_ = f\"{path}/{dir_}\"\n        for k in os.listdir(path_):\n            images.append(f\"{path_}/{k}\")\n            labels.append(dir_)\n    return pd.concat([pd.Series(images,name='Image'),pd.Series(labels,name='Class')],axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-05-03T19:55:34.017932Z","iopub.execute_input":"2024-05-03T19:55:34.018986Z","iopub.status.idle":"2024-05-03T19:55:34.026136Z","shell.execute_reply.started":"2024-05-03T19:55:34.018947Z","shell.execute_reply":"2024-05-03T19:55:34.024973Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ts_df = read_images(r\"/kaggle/input/brain-tumor-mri-dataset/Training\")\ntest_df = read_images(r\"/kaggle/input/brain-tumor-mri-dataset/Testing\")","metadata":{"execution":{"iopub.status.busy":"2024-05-03T19:55:35.953912Z","iopub.execute_input":"2024-05-03T19:55:35.954300Z","iopub.status.idle":"2024-05-03T19:55:36.547604Z","shell.execute_reply.started":"2024-05-03T19:55:35.954272Z","shell.execute_reply":"2024-05-03T19:55:36.546254Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df, valid_df = train_test_split(ts_df,  train_size= 0.8, shuffle= True, random_state= 42)","metadata":{"execution":{"iopub.status.busy":"2024-05-03T19:55:38.441708Z","iopub.execute_input":"2024-05-03T19:55:38.442127Z","iopub.status.idle":"2024-05-03T19:55:38.459450Z","shell.execute_reply.started":"2024-05-03T19:55:38.442097Z","shell.execute_reply":"2024-05-03T19:55:38.457775Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### EDA","metadata":{}},{"cell_type":"code","source":"pd.DataFrame(ts_df,columns=[\"Class\"])[\"Class\"].value_counts().plot(kind='pie',autopct='%1.0f%%')\nplt.xlabel(\"Class\")\nplt.xticks(rotation=0)\nplt.ylabel(\"Count\")\nplt.title(\"Class Distribution of Train Images\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-03T19:55:43.629088Z","iopub.execute_input":"2024-05-03T19:55:43.629549Z","iopub.status.idle":"2024-05-03T19:55:43.875012Z","shell.execute_reply.started":"2024-05-03T19:55:43.629504Z","shell.execute_reply":"2024-05-03T19:55:43.873145Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pd.DataFrame(test_df,columns=[\"Class\"])[\"Class\"].value_counts().plot(kind='pie',autopct='%1.0f%%')\nplt.xlabel(\"Class\")\nplt.xticks(rotation=0)\nplt.ylabel(\"Count\")\nplt.title(\"Class Distribution of Test Images\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-03T19:55:45.911295Z","iopub.execute_input":"2024-05-03T19:55:45.911694Z","iopub.status.idle":"2024-05-03T19:55:46.081109Z","shell.execute_reply.started":"2024-05-03T19:55:45.911662Z","shell.execute_reply":"2024-05-03T19:55:46.079945Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Data Preparation","metadata":{}},{"cell_type":"code","source":"img_size =  (256,256)\nbatch_size = 32","metadata":{"execution":{"iopub.status.busy":"2024-05-03T19:55:51.484094Z","iopub.execute_input":"2024-05-03T19:55:51.484472Z","iopub.status.idle":"2024-05-03T19:55:51.489671Z","shell.execute_reply.started":"2024-05-03T19:55:51.484443Z","shell.execute_reply":"2024-05-03T19:55:51.488366Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tr_gen = ImageDataGenerator(rescale=1/255,)\nts_gen = ImageDataGenerator(rescale=1/255)\n\ntrain_gen = tr_gen.flow_from_dataframe( train_df, x_col= 'Image', y_col= 'Class', target_size= img_size, class_mode= 'categorical',\n                                    color_mode= 'rgb', shuffle= True, batch_size= batch_size)\n\nvalid_gen = ts_gen.flow_from_dataframe( valid_df, x_col= 'Image', y_col= 'Class', target_size= img_size, class_mode= 'categorical',\n                                    color_mode= 'rgb', shuffle= True, batch_size= batch_size)\n\ntest_gen = ts_gen.flow_from_dataframe( test_df, x_col= 'Image', y_col= 'Class', target_size= img_size, class_mode= 'categorical',\n                                    color_mode= 'rgb', shuffle= False, batch_size= batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-05-03T19:55:56.208019Z","iopub.execute_input":"2024-05-03T19:55:56.208899Z","iopub.status.idle":"2024-05-03T19:56:01.168215Z","shell.execute_reply.started":"2024-05-03T19:55:56.208863Z","shell.execute_reply":"2024-05-03T19:56:01.167072Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"g_dict = train_gen.class_indices      \nclasses = list(g_dict.keys())       \nimages, labels = next(train_gen)    \n\nplt.figure(figsize= (20, 20))\n\nfor i in range(16):\n    plt.subplot(4, 4, i + 1)\n    plt.imshow(images[i])\n    index = np.argmax(labels[i])  \n    class_name = classes[index]  \n    plt.title(class_name, color= 'black', fontsize= 24)\n    plt.axis('off')\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-03T19:56:21.183459Z","iopub.execute_input":"2024-05-03T19:56:21.183987Z","iopub.status.idle":"2024-05-03T19:56:24.466383Z","shell.execute_reply.started":"2024-05-03T19:56:21.183939Z","shell.execute_reply":"2024-05-03T19:56:24.464783Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### ANN","metadata":{}},{"cell_type":"code","source":"model = Sequential()\nmodel.add(InputLayer(shape=(256,256,3)))\nmodel.add(Flatten())\nmodel.add(Dense(128,activation='relu'))\nmodel.add(Dense(32,activation='relu'))\nmodel.add(Dense(4,activation='softmax'))\n\nmodel.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-05-03T19:56:30.910903Z","iopub.execute_input":"2024-05-03T19:56:30.911311Z","iopub.status.idle":"2024-05-03T19:56:31.221711Z","shell.execute_reply.started":"2024-05-03T19:56:30.911278Z","shell.execute_reply":"2024-05-03T19:56:31.220662Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2024-05-03T19:56:32.832069Z","iopub.execute_input":"2024-05-03T19:56:32.832517Z","iopub.status.idle":"2024-05-03T19:56:32.855577Z","shell.execute_reply.started":"2024-05-03T19:56:32.832485Z","shell.execute_reply":"2024-05-03T19:56:32.854479Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.fit(train_gen,validation_data= valid_gen, shuffle= False,epochs=10)","metadata":{"execution":{"iopub.status.busy":"2024-05-03T19:56:37.615659Z","iopub.execute_input":"2024-05-03T19:56:37.616450Z","iopub.status.idle":"2024-05-03T19:56:44.390134Z","shell.execute_reply.started":"2024-05-03T19:56:37.616409Z","shell.execute_reply":"2024-05-03T19:56:44.387872Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_pred = model.predict(test_gen)\ny_pred = np.argmax(y_pred,axis=1)\ny_true = test_gen.classes","metadata":{"execution":{"iopub.status.busy":"2024-05-03T19:56:53.116227Z","iopub.execute_input":"2024-05-03T19:56:53.116612Z","iopub.status.idle":"2024-05-03T19:57:02.882350Z","shell.execute_reply.started":"2024-05-03T19:56:53.116583Z","shell.execute_reply":"2024-05-03T19:57:02.881273Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(classification_report(y_true,y_pred,zero_division=0,target_names=classes))","metadata":{"execution":{"iopub.status.busy":"2024-05-03T19:57:05.373452Z","iopub.execute_input":"2024-05-03T19:57:05.373850Z","iopub.status.idle":"2024-05-03T19:57:05.394028Z","shell.execute_reply.started":"2024-05-03T19:57:05.373799Z","shell.execute_reply":"2024-05-03T19:57:05.392712Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cm = confusion_matrix(y_true,y_pred)\ncmd = ConfusionMatrixDisplay(cm,display_labels=classes)\n\ncmd.plot()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-03T19:57:06.978089Z","iopub.execute_input":"2024-05-03T19:57:06.978476Z","iopub.status.idle":"2024-05-03T19:57:07.322456Z","shell.execute_reply.started":"2024-05-03T19:57:06.978446Z","shell.execute_reply":"2024-05-03T19:57:07.321279Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### CNN","metadata":{}},{"cell_type":"code","source":"model = Sequential([\n    InputLayer(shape=(256,256,3)),\n    Conv2D(32, (3, 3), activation='relu'),\n    MaxPooling2D((2, 2)),\n    Conv2D(64, (3, 3), activation='relu'),\n    MaxPooling2D((2, 2)),\n    Flatten(),\n    Dense(128, activation='relu'),\n    Dense(64, activation='relu'),\n    Dense(4, activation='softmax')\n])\n\nmodel.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2024-05-03T19:57:11.379272Z","iopub.execute_input":"2024-05-03T19:57:11.379657Z","iopub.status.idle":"2024-05-03T19:57:11.687736Z","shell.execute_reply.started":"2024-05-03T19:57:11.379627Z","shell.execute_reply":"2024-05-03T19:57:11.686600Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.fit(train_gen,validation_data= valid_gen, shuffle= False,epochs=10)","metadata":{"execution":{"iopub.status.busy":"2024-05-03T19:57:14.388186Z","iopub.execute_input":"2024-05-03T19:57:14.388583Z","iopub.status.idle":"2024-05-03T19:57:23.317311Z","shell.execute_reply.started":"2024-05-03T19:57:14.388551Z","shell.execute_reply":"2024-05-03T19:57:23.315623Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_pred = model.predict(test_gen)\ny_pred = np.argmax(y_pred,axis=1)\ny_true = test_gen.classes","metadata":{"execution":{"iopub.status.busy":"2024-05-03T19:57:26.264264Z","iopub.execute_input":"2024-05-03T19:57:26.264689Z","iopub.status.idle":"2024-05-03T19:57:48.826341Z","shell.execute_reply.started":"2024-05-03T19:57:26.264656Z","shell.execute_reply":"2024-05-03T19:57:48.825300Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(classification_report(y_true,y_pred,zero_division=0,target_names=classes))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cm = confusion_matrix(y_true,y_pred)\ncmd = ConfusionMatrixDisplay(cm,display_labels=classes)\n\ncmd.plot()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Transfer Learning using VGG19 Imagenet","metadata":{}},{"cell_type":"code","source":"model_vgg19 = VGG19(include_top=False, weights='imagenet', input_shape=(256,256,3))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_vgg19.summary()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = Sequential()\nfor layer in model_vgg19.layers:\n    model.add(layer)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for i in model.layers:\n   i.trainable = False","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.add(Flatten())\nmodel.add(Dense(100,activation='relu'))\nmodel.add(Dense(4,activation='softmax'))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\nmodel.fit(train_gen,validation_data= valid_gen, shuffle= False,epochs=10)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_pred = model.predict(test_gen)\ny_pred = np.argmax(y_pred,axis=1)\ny_true = test_gen.classes","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(classification_report(y_true,y_pred,zero_division=0,target_names=classes))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cm = confusion_matrix(y_true,y_pred)\ncmd = ConfusionMatrixDisplay(cm,display_labels=classes)\n\ncmd.plot()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Vision Transformer","metadata":{}},{"cell_type":"code","source":"num_epochs = 5\nn_classes=4\nimage_size = 256\npatch_size = 8  # Size of the patches to be extract from the input images\nnum_patches = (image_size // patch_size) ** 2\nprojection_dim = 64\nnum_heads = 4\ntransformer_units = [\n    projection_dim * 2,\n    projection_dim,\n]  # Size of the transformer layers\ntransformer_layers = 2\nmlp_head_units = [56, 28]  # Size of the dense layers of the final classifier","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def mlp(x, hidden_units, dropout_rate):\n    for units in hidden_units:\n        x = L.Dense(units, activation = tf.nn.gelu)(x)\n        x = L.Dropout(dropout_rate)(x)\n    return x","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class Patches(L.Layer):\n    def __init__(self, patch_size):\n        super(Patches, self).__init__()\n        self.patch_size = patch_size\n\n    def call(self, images):\n        batch_size = tf.shape(images)[0]\n        patches = tf.image.extract_patches(\n            images = images,\n            sizes = [1, self.patch_size, self.patch_size, 1],\n            strides = [1, self.patch_size, self.patch_size, 1],\n            rates = [1, 1, 1, 1],\n            padding = 'VALID',\n        )\n        patch_dims = patches.shape[-1]\n        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n        return patches","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class PatchEncoder(L.Layer):\n    def __init__(self, num_patches, projection_dim):\n        super(PatchEncoder, self).__init__()\n        self.num_patches = num_patches\n        self.projection = L.Dense(units = projection_dim)\n        self.position_embedding = L.Embedding(\n            input_dim = num_patches, output_dim = projection_dim\n        )\n\n    def call(self, patch):\n        positions = tf.range(start = 0, limit = self.num_patches, delta = 1)\n        encoded = self.projection(patch) + self.position_embedding(positions)\n        return encoded","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def vision_transformer():\n    inputs = L.Input(shape = (image_size, image_size, 3))\n    patches = Patches(patch_size)(inputs)\n    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n    \n    for _ in range(transformer_layers):\n        x1 = L.LayerNormalization(epsilon = 1e-6)(encoded_patches)\n        attention_output = L.MultiHeadAttention(\n            num_heads = num_heads, key_dim = projection_dim, dropout = 0.1\n        )(x1, x1)\n        x2 = L.Add()([attention_output, encoded_patches])\n        x3 = L.LayerNormalization(epsilon = 1e-6)(x2) \n        x3 = mlp(x3, hidden_units = transformer_units, dropout_rate = 0.1)\n        encoded_patches = L.Add()([x3, x2])\n\n    representation = L.LayerNormalization(epsilon = 1e-6)(encoded_patches)\n    representation = L.Flatten()(representation)\n    representation = L.Dropout(0.5)(representation)\n    features = mlp(representation, hidden_units = mlp_head_units, dropout_rate = 0.5)\n    logits = L.Dense(n_classes)(features)\n    model = tf.keras.Model(inputs = inputs, outputs = logits)\n    \n    return model","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = vision_transformer()    \nmodel.compile(optimizer = 'adam', \n              loss ='categorical_crossentropy',\n              metrics = ['accuracy'])\n\n\nmodel.fit(train_gen,validation_data= valid_gen, shuffle= False,epochs=10)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_pred = model.predict(test_gen)\ny_pred = np.argmax(y_pred,axis=1)\ny_true = test_gen.classes","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(classification_report(y_true,y_pred,zero_division=0,target_names=labels))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cm = confusion_matrix(y_true,y_pred)\ncmd = ConfusionMatrixDisplay(cm,display_labels=labels)\n\ncmd.plot()\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null}]}